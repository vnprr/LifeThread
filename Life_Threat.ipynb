{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnprr/LifeThread/blob/main/Life_Threat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNOe6jcof6Yw"
      },
      "source": [
        "#Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OhsPoiynGPA"
      },
      "source": [
        "## Disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_P5qENKR6ui"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSPEfaUAdz-f"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QGZYG3MOIOn"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets\n",
        "!pip -q install tqdm\n",
        "!pip -q install transformers\n",
        "!pip -q install seaborn\n",
        "!pip -q install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wEXsVCbnOn7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (pipeline,\n",
        "                          AutoTokenizer,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          DistilBertForSequenceClassification,\n",
        "                          Trainer,\n",
        "                          TrainingArguments,\n",
        "                          DistilBertTokenizer,\n",
        "                          BartTokenizer,\n",
        "                          BartForSequenceClassification,\n",
        "                          BertTokenizer,\n",
        "                          BertForSequenceClassification)\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import pickle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiDYSJrQgBrX"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcFGKIYJks9l"
      },
      "source": [
        "### Download 1st Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0Q6fUqleN1m"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('reddit-dataset-rdepression-and-rsuicidewatch.zip'):\n",
        "  !kaggle datasets download -d xavrig/reddit-dataset-rdepression-and-rsuicidewatch\n",
        "if not os.path.exists('reddit_depression_suicidewatch.csv'):\n",
        "  !unzip -q -n reddit-dataset-rdepression-and-rsuicidewatch.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fag2fW7emJGD"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP1YMPdVl1YA"
      },
      "source": [
        "### Download 2nd Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTsC6Yvll4Y2"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('suicide-watch.zip'):\n",
        "    !kaggle datasets download -d nikhileswarkomati/suicide-watch\n",
        "if not os.path.exists('suicide-watch.csv'):\n",
        "    !unzip -q -n suicide-watch.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38VIXvyzmjtD"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEjU9ZbDmsTC"
      },
      "source": [
        "## Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV0dpgHQmuQk"
      },
      "outputs": [],
      "source": [
        "# file path\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/SW/combined_data.csv'\n",
        "\n",
        "# CHECK IF FILE EXISTS\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"File {file_path} found. Loading data...\")\n",
        "    combined_data = pd.read_csv(file_path)\n",
        "\n",
        "else:\n",
        "    print(f\"File {file_path} not found. Performing sentiment analysis...\")\n",
        "\n",
        "    # read datasets\n",
        "    data1 = pd.read_csv('Suicide_Detection.csv')\n",
        "    data2 = pd.read_csv('reddit_depression_suicidewatch.csv')\n",
        "\n",
        "    # 1. label mapping\n",
        "    label_mapping = {'depression': 0, 'non-suicide': 0, 'SuicideWatch': 1, 'suicide': 1}\n",
        "\n",
        "    data1['class'] = data1['class'].map(label_mapping)\n",
        "    data2['class'] = data2['label'].map(label_mapping)\n",
        "    del data1[data1.columns[0]]\n",
        "    data2 = data2.drop(columns=['label'])\n",
        "\n",
        "    # 2. lowercase\n",
        "    data1['text'] = data1['text'].str.lower()\n",
        "    data2['text'] = data2['text'].str.lower()\n",
        "\n",
        "    # 3. concatenate data\n",
        "    combined_data = pd.concat([data1, data2], ignore_index=True)\n",
        "\n",
        "    # Remove duplicates\n",
        "    combined_data.drop_duplicates(subset=['text'], inplace=True)\n",
        "\n",
        "    # Save results\n",
        "    combined_data.to_csv(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUNzl2ODnKX5"
      },
      "outputs": [],
      "source": [
        "# print(data2.info())\n",
        "# print(data1.info())\n",
        "# print(combined_data.info())\n",
        "\n",
        "print(combined_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bP5Cfe9pBVx"
      },
      "outputs": [],
      "source": [
        "# file path\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/SW/combined_data_with_risk.csv'\n",
        "\n",
        "# CHECK IF FILE EXISTS\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"File {file_path} found. Loading data...\")\n",
        "    combined_data = pd.read_csv(file_path)\n",
        "\n",
        "else:\n",
        "    # check gpu\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "    # load model and tokenizer\n",
        "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    # tonenizer and model pipeline\n",
        "    sentiment_analysis = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "    # tqmd for pandas\n",
        "    tqdm.pandas()\n",
        "\n",
        "    # Analyze sentiment function\n",
        "    def analyze_sentiment(post):\n",
        "        # tokenization,\n",
        "        #  truncation=True: If the text is longer than the max_length, it will be truncated\n",
        "        #  padding='max_length': Shorter texts will be padded with special tokens to ensure all inputs have the same length.\n",
        "        #  max_length=512: Sets the maximum length of the tokenized sequence.\n",
        "        #  return_tensors='pt': Specifies that the function should return PyTorch tensors.\n",
        "        tokens = tokenizer(post, truncation=True, padding='max_length', max_length=512, return_tensors='pt') # Changed max_length to 512\n",
        "        # Sentument analysis\n",
        "        results = sentiment_analysis(post, truncation=True) # Added truncation to the pipeline call\n",
        "        return results[0]['score']\n",
        "\n",
        "    # Start analysis\n",
        "    combined_data['sentiment'] = combined_data['text'].progress_apply(analyze_sentiment)\n",
        "\n",
        "    # Save on g drive\n",
        "    combined_data.to_csv('/content/drive/MyDrive/Colab Notebooks/SW/combined_data_with_risk.csv', index=False)\n",
        "\n",
        "\n",
        "print(combined_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_z8ipT0qqmT"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHCE5qCU4zK9"
      },
      "outputs": [],
      "source": [
        "# initialize quantile transformer\n",
        "quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
        "\n",
        "# transform\n",
        "combined_data['sentiment'] = quantile_transformer.fit_transform(combined_data[['sentiment']])\n",
        "\n",
        "# show normalized\n",
        "print(combined_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43pN9Kqgrk7_"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "combined_data['sentiment'][combined_data['class'] == 0].plot(kind='hist', bins=20, edgecolor='black', alpha=0.5, label='non-suicidial')\n",
        "combined_data['sentiment'][combined_data['class'] == 1].plot(kind='hist', bins=20, edgecolor='black', alpha=0.5, label='suicidial')\n",
        "plt.title('Distribution of values in the sentiment column')\n",
        "plt.xlabel('Sentiment values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# min\n",
        "print(\"min:\", combined_data['sentiment'].min())\n",
        "\n",
        "# max\n",
        "print(\"max:\", combined_data['sentiment'].max())\n",
        "\n",
        "#accuracy\n",
        "print(\"accuracy score:\", accuracy_score(y_true=combined_data['class'], y_pred=combined_data['sentiment'] > 0.5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPfDnB4osTo"
      },
      "source": [
        "#### Sentiment analysis reveals a noticeable trend, but a significant portion of suicidal posts remain difficult to identify based solely on sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSZxfg9DNhYn"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-R9fBebNCh9"
      },
      "source": [
        "## Prepare Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx5Zw9wAMu-h"
      },
      "outputs": [],
      "source": [
        "combined_data = combined_data.drop(columns=['sentiment'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpClsRJ2Mwnk"
      },
      "outputs": [],
      "source": [
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqwqmueLNE0F"
      },
      "outputs": [],
      "source": [
        "# train / test split\n",
        "train_data, test_data = train_test_split(combined_data,\n",
        "                                         test_size=0.2,   #małe liczby najlepsze dla eksperymentowania\n",
        "                                         train_size=0.2,\n",
        "                                         random_state=42\n",
        "                                         )\n",
        "\n",
        "X_train = train_data['text']\n",
        "X_test = test_data['text']\n",
        "y_train = train_data['class']\n",
        "y_test = test_data['class']\n",
        "\n",
        "print(f\"train size: {len(train_data)}\")\n",
        "print(f\"test size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1zyar2ql70z"
      },
      "source": [
        "## Simple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9K7X33dJQsv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# text to numbers convertion TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U-4_BdVHO2y"
      },
      "source": [
        "### Model: **Stochastic Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP5XQy2WKN3Y"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# model_sgd = SGDClassifier(loss='log_loss', max_iter=1000)\n",
        "\n",
        "# # grid:\n",
        "# param_grid = {\n",
        "#     'alpha': [0.0001, 0.001, 0.01],\n",
        "#     'penalty': ['l1', 'l2'],\n",
        "# }\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid_search = GridSearchCV(model_sgd, param_grid, cv=5)\n",
        "\n",
        "# # fit to train data\n",
        "# grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # show parameters and test\n",
        "# print(grid_search.best_params_)\n",
        "# best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3Fr7gUwB-0h"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_sgd = SGDClassifier(loss='log_loss', alpha=0.0001, max_iter=1000, penalty='l2')\n",
        "\n",
        "# train\n",
        "history_sgd = model_sgd.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# test\n",
        "accuracy_sgd = model_sgd.score(X_test_tfidf, y_test)\n",
        "print(f\"Dokładność modelu regresji logistycznej: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFuivOtsYuSX"
      },
      "outputs": [],
      "source": [
        "# save on disc\n",
        "\n",
        "import pickle\n",
        "\n",
        "filename = '/content/drive/MyDrive/Programowanie/Life Thread/Models/SDGclassifier1.sav'\n",
        "pickle.dump(model_sgd, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJCgjvfMKW5r"
      },
      "source": [
        "#### Podsumowanie\n",
        "Najlepsze wartości:\n",
        "`model = SGDClassifier(loss='log_loss', alpha=0.0001, max_iter=10000, penalty='l2')`\n",
        "\n",
        "Wartość max_iter została zoptymalizowana do 1000\n",
        "\n",
        "Model osiągnął satysfakcjonujący wynik accuracy: 0.8932\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuflkDa_lj2x"
      },
      "source": [
        "### Model: **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEaXpWkdmJX2"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "model_nb = MultinomialNB()\n",
        "\n",
        "# grid:\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0],\n",
        "    'fit_prior': [True, False],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model_nb, param_grid, cv=5)\n",
        "\n",
        "# fit to train data\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test\n",
        "print(grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(X_test_tfidf, y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vic1dwQAliNe"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_nb = MultinomialNB(alpha=0.5, fit_prior=False)\n",
        "model_nb.fit(X_train_tfidf, y_train)\n",
        "accuracy = model_nb.score(X_test_tfidf, y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFmi2D6GvRhL"
      },
      "outputs": [],
      "source": [
        "# save on disc\n",
        "\n",
        "\n",
        "filename = '/content/drive/MyDrive/Programowanie/Life Thread/Models/NaiveBayes1.sav'\n",
        "pickle.dump(model_nb, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5bPQONvu-k"
      },
      "source": [
        "#### Podsumowanie\n",
        "\n",
        "Najlepsze wartości: `'alpha': 0.1, 'fit_prior': True`\n",
        "\n",
        "Model osiągnął satysfakcjonujący wynik accuracy: 0.8739\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqSapfkQwMw3"
      },
      "source": [
        "### Model: **Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI37ee67wXvQ"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.svm import SVC # Import the SVC class\n",
        "\n",
        "# # Assuming you want to tune an SVM classifier, create an instance of SVC\n",
        "# model_svm = SVC()\n",
        "\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10, 100],\n",
        "#     'kernel': ['linear', 'rbf', 'poly'],\n",
        "#     'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(model_svm, param_grid, cv=5, scoring='accuracy') # 5-fold cross validation # Changed 'model' to 'model_svm'\n",
        "# grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# print(\"Best parameters found: \", grid_search.best_params_)\n",
        "# print(\"Best score: \", grid_search.best_score_)\n",
        "\n",
        "# best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX7XdsgkwRPi"
      },
      "outputs": [],
      "source": [
        "# Best parameters found:  {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
        "# Best score:  0.8980190174326467\n",
        "\n",
        "\n",
        "# Create and start the process\n",
        "model_svc = SVC(C=100, gamma='scale', kernel='rbf')\n",
        "\n",
        "model_svc.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_svc.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = model_svc.score(X_test_tfidf, y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78-1TGqGe_XG"
      },
      "outputs": [],
      "source": [
        "# save on disc\n",
        "\n",
        "filename = '/content/drive/MyDrive/Programowanie/Life Thread/Models/SVC1.sav'\n",
        "pickle.dump(model_svc, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7JKyOfHc-xo"
      },
      "source": [
        "#### Summary\n",
        "\n",
        "**Support Vector Classifier** model was trained using the scikit-learn library.\n",
        "\n",
        "The best hyperparameters found for the model are:\n",
        "\n",
        "`C: 100, gamma: 'scale', kernel: 'rbf'`\n",
        "\n",
        "These hyperparameters were found using GridSearchCV, which allowed for searching the hyperparameter space and selecting the best values.\n",
        "\n",
        "The model achieved an accuracy score of **0.9004** on the validation set.\n",
        "\n",
        "The training and testing were performed on the CPU and 5% of dataset for optimization.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACPgjLpRwT0w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W05hmV0KYaJZ"
      },
      "source": [
        "## BERT Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtThaqLeiyT9"
      },
      "source": [
        "### Model: **BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDUidjxhYevJ"
      },
      "outputs": [],
      "source": [
        "# Convert pandas DataFrame to Dataset\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# tokenization\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# rename\n",
        "if 'class' in train_dataset.column_names:\n",
        "  train_dataset = train_dataset.rename_column(\"class\", \"labels\")\n",
        "  test_dataset = test_dataset.rename_column(\"class\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro5w1ZTeYhxV"
      },
      "outputs": [],
      "source": [
        "# # Metrics function\n",
        "# def compute_metrics(pred):\n",
        "#     labels = pred.label_ids\n",
        "#     preds = pred.predictions.argmax(-1)\n",
        "#     f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "#     acc = accuracy_score(labels, preds)\n",
        "#     return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# Load model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_steps=10_000,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    report_to=\"none\"  # Disable reporting for speed optimization\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        "    #compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAMxwh8MHbeJ"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/bert_model_0.2')\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/bert_tokenizer_0.2')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_steps=10_000,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    report_to=\"none\"  # Disable reporting for speed optimization\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        "    #compute_metrics=compute_metrics\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt91BZzL9qCT"
      },
      "outputs": [],
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "eval = trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5nWCZhx91F8"
      },
      "outputs": [],
      "source": [
        "print(eval)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "loss = predictions.metrics['test_loss']\n",
        "accuracy = accuracy_score(labels, predictions.predictions.argmax(-1))\n",
        "\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "print(f\"loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQApLPZmnLFC"
      },
      "outputs": [],
      "source": [
        "# Extract labels and predictions\n",
        "labels = test_dataset['labels']\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMv7C_Fxi_aR"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/bert_model_0.2')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/bert_tokenizer_0.2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9DPxLTAmPxe"
      },
      "source": [
        "#### Summary\n",
        "\n",
        "##### **BERT Version 1**\n",
        "\n",
        "trained on 5% dataset\n",
        "\n",
        "```\n",
        "Epoch\t Training Loss\n",
        "1\t     0.207500\n",
        "2\t     0.096700\n",
        "3\t     0.044100\n",
        "\n",
        "TrainOutput(\n",
        "  global_step=2367,\n",
        "  training_loss=0.12685552427020313,\n",
        "  metrics={\n",
        "    'train_runtime': 1300.4625,\n",
        "    'train_samples_per_second': 29.113,\n",
        "    'train_steps_per_second': 1.82,\n",
        "    'total_flos': 9961384555929600.0,\n",
        "    'train_loss': 0.12685552427020313,\n",
        "    'epoch': 3.0\n",
        "  })\n",
        "```\n",
        "\n",
        "##### **BERT Version 2**\n",
        "\n",
        "```\n",
        "Accuracy: 0.9544\n",
        "Loss:     0.1629\n",
        "```\n",
        "\n",
        "```\n",
        "Epoch\t Training Loss\n",
        "0\t     0.138200\n",
        "1\t     0.083700\n",
        "2\t     0.036100\n",
        "\n",
        "TrainOutput(\n",
        "  global_step=2364,\n",
        "  training_loss=0.0961090798305376,\n",
        "  metrics={\n",
        "    'train_runtime': 2771.6409,\n",
        "    'train_samples_per_second': 54.64,\n",
        "    'train_steps_per_second': 0.853,\n",
        "    'total_flos': 3.980396667697152e+16,\n",
        "    'train_loss': 0.0961090798305376,\n",
        "    'epoch': 2.9966724766281096\n",
        "  })\n",
        "```\n",
        "\n",
        "Training the **BERT** model on **20%** of the available data yielded very promising results. The achieved accuracy of **0.9544** indicates that the model generalizes well and can classify examples correctly with high precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx4vWh1SivEf"
      },
      "source": [
        "### Model: **DistilBERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcxd0HJNkx41"
      },
      "outputs": [],
      "source": [
        "# Convert pandas DataFrame to Dataset\n",
        "train_dataset_db = Dataset.from_pandas(train_data)\n",
        "test_dataset_db = Dataset.from_pandas(test_data)\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# tokenization\n",
        "train_dataset_db = train_dataset_db.map(tokenize_function, batched=True)\n",
        "test_dataset_db = test_dataset_db.map(tokenize_function, batched=True)\n",
        "\n",
        "# rename\n",
        "if 'class' in train_dataset_db.column_names:\n",
        "  train_dataset_db = train_dataset_db.rename_column(\"class\", \"labels\")\n",
        "  test_dataset_db = test_dataset_db.rename_column(\"class\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "louoyom4io6r"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(pred):\n",
        "#     labels = pred.label_ids\n",
        "#     preds = pred.predictions.argmax(-1)\n",
        "#     f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "#     acc = accuracy_score(labels, preds)\n",
        "#     return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# Load model\n",
        "model_db = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "# GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_db.to(device)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",  # Save at the end of each epoch\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    gradient_accumulation_steps=2\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer_db = Trainer(\n",
        "    model=model_db,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_db,\n",
        "    eval_dataset=test_dataset_db\n",
        "    #compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer_db.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM4m3fmANtrD"
      },
      "outputs": [],
      "source": [
        "results = trainer_db.evaluate()\n",
        "predictions = trainer_db.predict(test_dataset_db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZrqT-kNBaMH"
      },
      "outputs": [],
      "source": [
        "print(results)\n",
        "\n",
        "loss = predictions.metrics['test_loss']\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "print(f\"loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-MqHZvhBZNh"
      },
      "outputs": [],
      "source": [
        "# Extract labels and predictions\n",
        "labels = test_dataset['class']\n",
        "preds = predictions_db.predictions.argmax(-1)\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYlbv5RPugEE"
      },
      "outputs": [],
      "source": [
        "model_db.save_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/distilbert_model_0.2')\n",
        "tokenizer_db.save_pretrained('/content/drive/MyDrive/Programowanie/Life Thread/Models/distilbert_tokenizer_0.2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_pHXn2rpUS"
      },
      "source": [
        "#### Podsumowanie\n",
        "\n",
        "Na **5% danych** model osiągnął niewiele gorsze rezultaty przy mniejszej złożoności od BERT.\n",
        "\n",
        "Wydajność na zbiorze testowym:\n",
        "\n",
        "```\n",
        "Accuracy: 0.9362\n",
        "Loss:     0.1701\n",
        "```\n",
        "\n",
        "Na **20% danych** model osiągnął minimalnie gorsze  rezultaty przy mniejszej złożoności od BERT.\n",
        "\n",
        "Wydajność na zbiorze testowym:\n",
        "\n",
        "```\n",
        "Accuracy: 0.9510\n",
        "Loss:     0.1384\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7OhsPoiynGPA",
        "L_z8ipT0qqmT",
        "L-R9fBebNCh9",
        "O1zyar2ql70z",
        "-U-4_BdVHO2y"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOY8sZkBA/0eGrDTOoM+ofm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}